# Option B: Change Preview System - IN PROGRESS ğŸš§

## What We've Built So Far

### âœ… **Impact Analyzer Module** (COMPLETE - 418 lines)

**File**: `flux/core/impact_analyzer.py`

#### Features Implemented:

1. **Change Impact Analysis**
   - Determines change type (add/modify/delete/refactor)
   - Calculates impact level (low/medium/high/critical)
   - Computes confidence score (0.0 to 1.0)

2. **Affected Code Detection**
   - Identifies functions affected by changes
   - Finds classes that will be modified
   - Discovers dependent files
   - Suggests tests that need updating

3. **Risk Assessment**
   - Detects potential breaking changes
   - Identifies if migration is needed
   - Checks if public API is affected

4. **Diff Preview Generation**
   - Creates unified diffs (before/after)
   - Counts lines added/removed/modified
   - Provides visual comparison

5. **Smart Warnings & Suggestions**
   - Warns about critical changes
   - Suggests tests to update
   - Recommends reviewing call sites

#### Data Structures:

```python
@dataclass
class ChangeImpact:
    file_path: str
    change_type: ChangeType  # ADD, MODIFY, DELETE, REFACTOR
    impact_level: ImpactLevel  # LOW, MEDIUM, HIGH, CRITICAL
    confidence_score: float  # 0.0 to 1.0
    
    functions_affected: List[str]
    classes_affected: List[str]
    dependencies_affected: List[str]
    tests_need_update: List[str]
    
    breaks_existing_code: bool
    requires_migration: bool
    affects_public_api: bool
    
    summary: str
    warnings: List[str]
    suggestions: List[str]

@dataclass
class DiffPreview:
    file_path: str
    old_content: str
    new_content: str
    unified_diff: str
    line_changes: Dict[str, int]  # {added, removed, modified}
```

#### Intelligence Features:

- **AST-based Analysis** - Parses Python code to understand structure
- **Codebase Graph Integration** - Uses dependency information
- **Confidence Scoring** - Based on change size, syntax validity, test coverage
- **Impact Classification** - Automatically categorizes severity

---

## ğŸ¯ What This Enables

### Before (Current State):
```
AI: [makes changes]
Result: Change applied
User: [Surprise! What changed?]
```

### After (With Preview System):
```
AI: I'll modify flux/core/config.py

ğŸ“Š Impact Analysis:
  Type: MODIFY
  Impact: MEDIUM
  Confidence: 95%

ğŸ“ Changes:
  â€¢ _validate_tokens() - Enhanced validation logic
  â€¢ __post_init__() - Added error handling
  
âš ï¸  Warnings:
  â€¢ 3 files depend on this: main.py, cli.py, llm/client.py
  
ğŸ’¡ Suggestions:
  â€¢ Update tests: tests/test_config.py
  
ğŸ” Diff Preview:
  +15 lines added
  -8 lines removed
  
Approve? [y/N/preview/explain]
```

---

## ğŸš§ Remaining Work

### 1. **CLI Integration** (30 min)
- [ ] Add `/preview <file>` command
- [ ] Show impact analysis before edits
- [ ] Add approval with preview option

### 2. **Tool Integration** (45 min)
- [ ] Integrate with `edit_file` tool
- [ ] Integrate with `ast_edit` tool  
- [ ] Show preview before applying changes
- [ ] Add "preview mode" to tool execution

### 3. **Visual Enhancements** (30 min)
- [ ] Color-coded diff display
- [ ] Impact level badges (ğŸŸ¢ LOW, ğŸŸ¡ MEDIUM, ğŸ”´ HIGH, âš« CRITICAL)
- [ ] Confidence score visualization
- [ ] Dependency graph visualization

### 4. **Advanced Features** (Optional - 1 hour)
- [ ] Side-by-side diff view
- [ ] Syntax highlighting in diffs
- [ ] Interactive approval (approve/reject/modify)
- [ ] Change history tracking

---

## ğŸ“Š Impact Analysis Example

### Scenario: Modifying `config.py`

```python
analyzer = ImpactAnalyzer(cwd, codebase_graph)

impact = analyzer.analyze_change(
    file_path="flux/core/config.py",
    old_content=old_code,
    new_content=new_code
)

# Results:
# - Change Type: MODIFY
# - Impact Level: MEDIUM
# - Confidence: 0.92
# - Functions Affected: ['__post_init__', '_validate_tokens']
# - Dependencies: ['flux/main.py', 'flux/ui/cli.py']
# - Tests Need Update: ['tests/test_config.py']
# - Breaks Existing: False
# - Warnings: ["âš ï¸  3 file(s) depend on this"]
# - Suggestions: ["ğŸ’¡ Update tests: tests/test_config.py"]
```

---

## ğŸ’ª Competitive Advantage

### Warp Doesn't Have This
- âŒ No impact analysis
- âŒ No preview before changes
- âŒ No confidence scores
- âŒ No dependency awareness
- âŒ No breaking change detection

### Flux Will Have
- âœ… Complete impact analysis
- âœ… Visual diff preview
- âœ… Confidence scoring
- âœ… Dependency tracking
- âœ… Breaking change warnings
- âœ… Smart suggestions

---

## ğŸ” Technical Details

### Confidence Score Calculation

```python
def _calculate_confidence(file_path, old_content, new_content):
    confidence = 1.0
    
    # Reduce for large changes
    if lines_changed > 100: confidence *= 0.7
    elif lines_changed > 50: confidence *= 0.8
    elif lines_changed > 20: confidence *= 0.9
    
    # Reduce if syntax invalid
    try:
        ast.parse(new_content)
    except SyntaxError:
        confidence *= 0.5
    
    # Increase if tests exist
    if test_file_exists:
        confidence *= 1.1
    
    return min(1.0, confidence)
```

### Impact Level Classification

```python
def _calculate_impact_level(file_path, lines_changed):
    is_core = 'core/' in file_path or 'main.py' in file_path
    
    if lines_changed > 100 or is_core:
        return ImpactLevel.CRITICAL
    elif lines_changed > 50:
        return ImpactLevel.HIGH
    elif lines_changed > 20:
        return ImpactLevel.MEDIUM
    else:
        return ImpactLevel.LOW
```

### Breaking Change Detection

```python
def _check_breaking_changes(old_content, new_content):
    old_functions = extract_functions(old_content)
    new_functions = extract_functions(new_content)
    
    # Functions were removed = breaking
    return bool(old_functions - new_functions)
```

---

## ğŸ¨ Visual Design

### Impact Badge System

```
ğŸŸ¢ LOW      - Safe, single function change
ğŸŸ¡ MEDIUM   - Multiple functions, review needed
ğŸ”´ HIGH     - Cross-file impact, careful review
âš« CRITICAL - Core infrastructure, thorough review
```

### Confidence Display

```
95%+ â†’ âœ… High Confidence
80-94% â†’ ğŸ’š Good Confidence  
60-79% â†’ ğŸ’› Medium Confidence
<60% â†’ âš ï¸ Low Confidence
```

---

## ğŸ“ˆ Next Steps

### Immediate (Next 30 min):
1. Add `/preview` CLI command
2. Integrate impact analyzer with CLI
3. Show preview in tool execution

### Soon (Next hour):
1. Color-coded diff display
2. Impact badges
3. Interactive approval workflow

### Future Enhancements:
1. Dependency graph visualization
2. Change history tracking
3. Risk score trending
4. ML-based confidence improvement

---

## ğŸ§ª Testing Plan

```bash
# Test Impact Analyzer
cd /Users/developer/SynologyDrive/flux-cli
source venv/bin/activate

python -c "
from pathlib import Path
from flux.core.impact_analyzer import create_impact_analyzer

analyzer = create_impact_analyzer(Path.cwd())

old_code = 'def foo(): pass'
new_code = 'def foo():\\n    return 42'

impact = analyzer.analyze_change('test.py', old_code, new_code)
print(f'Impact: {impact.impact_level.value}')
print(f'Confidence: {impact.confidence_score}')
print(f'Summary: {impact.summary}')
"
```

---

## ğŸ’¡ Usage Example

### Command Line:
```bash
flux
> /preview flux/core/config.py

# Shows:
# - Current vs proposed changes
# - Impact analysis
# - Confidence score
# - Affected dependencies
# - Warnings & suggestions
```

### In AI Workflow:
```
You: Add error handling to config

AI: I'll modify flux/core/config.py
    [Shows impact preview automatically]
    
    ğŸ“Š Impact: MEDIUM (Confidence: 92%)
    Functions: __post_init__, _validate_tokens
    Dependencies: 3 files affected
    
    Approve? [y/N/preview]

You: preview

AI: [Shows detailed diff and analysis]

You: y

AI: âœ… Changes applied successfully
```

---

## ğŸ‰ Summary

**We've built the foundation for making Flux the most transparent AI coding assistant.**

### Completed:
- âœ… Impact Analyzer (418 lines)
- âœ… Change type detection
- âœ… Confidence scoring
- âœ… Diff preview generation
- âœ… Breaking change detection
- âœ… Dependency tracking
- âœ… Smart warnings & suggestions

### Remaining:
- ğŸš§ CLI integration
- ğŸš§ Tool integration
- ğŸš§ Visual enhancements
- ğŸš§ Interactive approval

**Status**: 60% complete  
**Time Spent**: ~1 hour  
**Time Remaining**: ~1 hour

---

**This is the transparency layer that makes developers trust AI changes.**

No other tool (including Warp) shows this level of detail before making changes.
